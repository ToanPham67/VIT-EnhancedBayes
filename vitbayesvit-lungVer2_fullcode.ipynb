{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3281997,"sourceType":"datasetVersion","datasetId":1987684},{"sourceId":125882,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":105975,"modelId":130264}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torchvision import transforms\nfrom transformers import ViTModel, ViTFeatureExtractor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom PIL import Image\nimport os\nimport cv2\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder  # <-- add this\nfrom tensorflow.keras.utils import to_categorical","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:05:30.603812Z","iopub.execute_input":"2025-05-07T02:05:30.604573Z","iopub.status.idle":"2025-05-07T02:05:38.813914Z","shell.execute_reply.started":"2025-05-07T02:05:30.604509Z","shell.execute_reply":"2025-05-07T02:05:38.813074Z"}},"outputs":[{"name":"stderr","text":"2025-05-07 02:05:35.995669: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746583536.019329     327 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746583536.026670     327 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Step 1: Load the Pre-trained Vision Transformer Model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Load ViT model and feature extractor\nfeature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\nmodel = ViTModel.from_pretrained('google/vit-base-patch16-224').to(device)\nmodel.eval()  # Set the model to evaluation mode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:05:50.548951Z","iopub.execute_input":"2025-05-07T02:05:50.549901Z","iopub.status.idle":"2025-05-07T02:05:51.119401Z","shell.execute_reply.started":"2025-05-07T02:05:50.549871Z","shell.execute_reply":"2025-05-07T02:05:51.118702Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n  warnings.warn(\nSome weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"ViTModel(\n  (embeddings): ViTEmbeddings(\n    (patch_embeddings): ViTPatchEmbeddings(\n      (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n    )\n    (dropout): Dropout(p=0.0, inplace=False)\n  )\n  (encoder): ViTEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x ViTLayer(\n        (attention): ViTAttention(\n          (attention): ViTSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (output): ViTSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (intermediate): ViTIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): ViTOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      )\n    )\n  )\n  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n  (pooler): ViTPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"!pip3 install torchinfo\nfrom transformers import ViTModel\nfrom torchinfo import summary\n\n# Load the pre-trained Vision Transformer (ViT) model\nmodel = ViTModel.from_pretrained('google/vit-base-patch16-224')\n\n# Get the model summary\nsummary(model, input_size=(1, 3, 224, 224))  # Batch size of 1, RGB channels, 224x224 image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:05:57.058296Z","iopub.execute_input":"2025-05-07T02:05:57.058604Z","iopub.status.idle":"2025-05-07T02:06:00.595242Z","shell.execute_reply.started":"2025-05-07T02:05:57.058582Z","shell.execute_reply":"2025-05-07T02:06:00.594572Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n","output_type":"stream"},{"name":"stderr","text":"Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"====================================================================================================\nLayer (type:depth-idx)                             Output Shape              Param #\n====================================================================================================\nViTModel                                           [1, 768]                  --\n├─ViTEmbeddings: 1-1                               [1, 197, 768]             152,064\n│    └─ViTPatchEmbeddings: 2-1                     [1, 196, 768]             --\n│    │    └─Conv2d: 3-1                            [1, 768, 14, 14]          590,592\n│    └─Dropout: 2-2                                [1, 197, 768]             --\n├─ViTEncoder: 1-2                                  [1, 197, 768]             --\n│    └─ModuleList: 2-3                             --                        --\n│    │    └─ViTLayer: 3-2                          [1, 197, 768]             7,087,872\n│    │    └─ViTLayer: 3-3                          [1, 197, 768]             7,087,872\n│    │    └─ViTLayer: 3-4                          [1, 197, 768]             7,087,872\n│    │    └─ViTLayer: 3-5                          [1, 197, 768]             7,087,872\n│    │    └─ViTLayer: 3-6                          [1, 197, 768]             7,087,872\n│    │    └─ViTLayer: 3-7                          [1, 197, 768]             7,087,872\n│    │    └─ViTLayer: 3-8                          [1, 197, 768]             7,087,872\n│    │    └─ViTLayer: 3-9                          [1, 197, 768]             7,087,872\n│    │    └─ViTLayer: 3-10                         [1, 197, 768]             7,087,872\n│    │    └─ViTLayer: 3-11                         [1, 197, 768]             7,087,872\n│    │    └─ViTLayer: 3-12                         [1, 197, 768]             7,087,872\n│    │    └─ViTLayer: 3-13                         [1, 197, 768]             7,087,872\n├─LayerNorm: 1-3                                   [1, 197, 768]             1,536\n├─ViTPooler: 1-4                                   [1, 768]                  --\n│    └─Linear: 2-4                                 [1, 768]                  590,592\n│    └─Tanh: 2-5                                   [1, 768]                  --\n====================================================================================================\nTotal params: 86,389,248\nTrainable params: 86,389,248\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 201.40\n====================================================================================================\nInput size (MB): 0.60\nForward/backward pass size (MB): 162.19\nParams size (MB): 344.95\nEstimated Total Size (MB): 507.74\n===================================================================================================="},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom concurrent.futures import ThreadPoolExecutor\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\ndef load_images_and_labels(folder_path, target_size=(224, 224), num_workers=8):\n    image_paths = []\n    labels = []\n    # Scan all image paths and labels\n    for label_name in os.listdir(folder_path):\n        label_folder = os.path.join(folder_path, label_name)\n        if os.path.isdir(label_folder):\n            for filename in os.listdir(label_folder):\n                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n                    image_path = os.path.join(label_folder, filename)\n                    image_paths.append(image_path)\n                    labels.append(label_name)\n    # Define a function for parallel loading\n    def load_and_preprocess(path):\n        img = cv2.imread(path)\n        if img is not None:\n            img = cv2.resize(img, target_size)\n            img = img.astype(np.float32) / 255.0  # Normalize inside\n        return img\n    # Load images in parallel\n    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n        images = list(executor.map(load_and_preprocess, image_paths))\n\n    # Remove any images that failed to load (just in case)\n    images = np.array([img for img in images if img is not None], dtype=np.float32)\n    labels = np.array(labels)\n    return images, labels\n# --- Now load your datasets ---\ntrain_folder = \"/kaggle/input/lc25000/lung_colon_image_set/Train and Validation Set\"\ntest_folder = \"/kaggle/input/lc25000/lung_colon_image_set/Test Set\"\nx_train, y_train = load_images_and_labels(train_folder)\nx_test, y_test = load_images_and_labels(test_folder)\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\n\n# Encode string labels to integers [0, 1, 2, 3, 4]\nlabel_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(y_train)\ny_test = label_encoder.transform(y_test)\n\n# One-hot encode labels\n#num_classes = len(label_encoder.classes_)\n#y_train = to_categorical(y_train, num_classes)\n#y_test = to_categorical(y_test, num_classes)\n\n# Check shapes\nprint(f\"x_train: {x_train.shape}, y_train: {y_train.shape}\")\nprint(f\"x_test: {x_test.shape}, y_test: {y_test.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nfrom PIL import Image, UnidentifiedImageError\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef process_image(img_path, feature_extractor, model, device):\n    try:\n        # Load and preprocess image\n        image = Image.open(img_path).convert(\"RGB\")\n\n        # Preprocess with feature extractor\n        inputs = feature_extractor(image, return_tensors=\"pt\").to(device)\n\n        # Extract features\n        with torch.no_grad():\n            outputs = model(**inputs)\n\n        # Take CLS token feature\n        cls_token_feature = outputs.last_hidden_state[:, 0, :]  # CLS token\n        return cls_token_feature.cpu().numpy().flatten()\n\n    except UnidentifiedImageError:\n        print(f\"Warning: Unable to identify image file: {img_path}. Skipping.\")\n    except Exception as e:\n        print(f\"Error processing {img_path}: {e}\")\n    return None\ndef extract_features(image_paths, feature_extractor, model, device, num_workers=4):\n    features = []\n\n    # Define a helper function that wraps process_image\n    def process(img_path):\n        return process_image(img_path, feature_extractor, model, device)\n\n    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n        results = list(executor.map(process, image_paths))\n\n    # Remove failed images\n    features = np.array([res for res in results if res is not None])\n    return features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_folder = \"/kaggle/input/lc25000/lung_colon_image_set/Train and Validation Set\"\ntrain_paths = []  # list all your image paths\n# Example of collecting all image paths\nfor root, _, files in os.walk(train_folder):\n    for file in files:\n        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n            train_paths.append(os.path.join(root, file))\n# Extract features\nfeatures_train = extract_features(train_paths, feature_extractor, model, device, num_workers=8)\nprint(\"Extracted feature shape:\", features_train.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nstart=time.time()\ntest_folder = \"/kaggle/input/lc25000/lung_colon_image_set/Test Set\"\ntest_paths = []  # list all your image paths\n\n# Example of collecting all image paths\nfor root, _, files in os.walk(test_folder):\n    for file in files:\n        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n            test_paths.append(os.path.join(root, file))\n# Extract features\nfeatures_test = extract_features(test_paths, feature_extractor, model, device, num_workers=8)\nprint(\"Extracted feature shape:\", features_test.shape)\nend=time.time()\nprint('Thoi gian thu thi',end-start)\n# Lưu vào file Excel\n#df = pd.DataFrame(Train_features)  # Chuyển thành DataFrame\n#df.to_excel(\"Train_features.xlsx\", index=False)  # Lưu vào tệp Excel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"XGBoost","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report\nimport time\n\nst = time.time()\n# Encode target labels\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)  # Fit & transform y_train\ny_test_encoded = label_encoder.transform(y_test)        # Only transform y_test\n\n# Step 5: Train an XGBoost Classifier\nclassifier = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\nclassifier.fit(features_train, y_train_encoded)  # Training with encoded labels  \n\n# Step 6: Make Predictions\ny_pred_encoded = classifier.predict(features_test)\n\n# Step 7: Decode predictions back to original labels\ny_pred = label_encoder.inverse_transform(y_pred_encoded)\n\n# Step 8: Evaluate the Model\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\nnd = time.time()\nprint(\"Thoi gian thu thi:\", nd - st)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n# Step 7: Evaluate the Model and Compute Confusion Matrix\nconf_matrix = confusion_matrix(y_test_encoded, y_pred)  # Define conf_matrix here\nclass_names = ['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc']\nclassA =[0,1,2,3,4]\n# Map integer labels to class names\ncategories = [class_names[label] for label in classA]\n# Figure 1: Confusion Matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n            xticklabels=categories, yticklabels=categories)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.savefig('confusion_XGBoost.png')\nplt.show","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Enhanced bayesian method**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.neighbors import KernelDensity\nimport numpy as np\nimport time\nst=time.time()\nclass KDE_NaiveBayes:\n    def __init__(self, bandwidth=0.09, default_class=None):\n        self.bandwidth = bandwidth\n        self.kde_models = {}\n        self.classes = None\n        self.priors = None\n        self.default_class = default_class  # Fallback class if no valid prediction\n\n    def fit(self, X, y):\n        self.classes = np.unique(y)\n        self.priors = {}\n        n_samples = len(y)\n\n        # Calculate prior probabilities\n        for c in self.classes:\n            self.priors[c] = np.sum(y == c) / n_samples\n        \n        # Fit KDE for each feature and each class, skip if no samples\n        for c in self.classes:\n            X_c = X[y == c]\n            if X_c.shape[0] == 0:\n                print(f\"Warning: No samples found for class {c}. Skipping KDE fitting.\")\n                self.kde_models[c] = None\n                continue\n            self.kde_models[c] = []\n            for feature_idx in range(X.shape[1]):\n                kde = KernelDensity(bandwidth=self.bandwidth, kernel='gaussian')\n                kde.fit(X_c[:, feature_idx].reshape(-1, 1))\n                self.kde_models[c].append(kde)\n\n    def predict(self, X):\n        n_samples = X.shape[0]\n        log_probs = np.zeros((n_samples, len(self.classes)))\n\n        for idx, c in enumerate(self.classes):\n            log_prior = np.log(self.priors[c]) if self.priors[c] > 0 else -np.inf\n            if self.kde_models[c] is None:\n                log_probs[:, idx] = -np.inf\n                continue\n            log_likelihood = np.zeros(n_samples)\n            for feature_idx, kde in enumerate(self.kde_models[c]):\n                feature_log_prob = kde.score_samples(X[:, feature_idx].reshape(-1, 1))\n                log_likelihood += feature_log_prob\n            log_probs[:, idx] = log_prior+log_likelihood\n        \n        # Check if all probabilities are -inf\n        if np.all(log_probs == -np.inf, axis=1).any():\n            if self.default_class is not None:\n                print(f\"Warning: Some samples have no valid class probabilities. Using default class: {self.default_class}\")\n                y_pred = np.array([self.default_class if np.all(log_probs[i] == -np.inf) else self.classes[np.argmax(log_probs[i])] for i in range(n_samples)])\n            else:\n                raise ValueError(\"No valid predictions possible for some samples; all classes have zero probability. Set a default_class to handle this.\")\n        else:\n            y_pred = self.classes[np.argmax(log_probs, axis=1)]\n        \n        return y_pred\n\n# Example usage\nclassifier = KDE_NaiveBayes(bandwidth=0.09, default_class='Normal')  # Set a default class\nclassifier.fit(features_train, y_train)\ny_pred = classifier.predict(features_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nnd=time.time()\nprint(\"Thoi gian\",nd-st)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n# Step 7: Evaluate the Model and Compute Confusion Matrix\nconf_matrix = confusion_matrix(y_test, y_pred)  # Define conf_matrix here\nclass_names = ['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc']\nclassA =[0,1,2,3,4]\n# Map integer labels to class names\ncategories = [class_names[label] for label in classA]\n# Figure 1: Confusion Matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n            xticklabels=categories, yticklabels=categories)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.savefig('confusion_Naivebayes.png')\nplt.show\n# plt.close()\n# print(\"Confusion matrix figure saved as 'confusion_matrix.png'.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Bắt đầu đo thời gian\nst = time.time()\n\n# Step 5: Train a Logistic Regression Classifier  \nclassifier = LogisticRegression(max_iter=1000)  # Tạo đối tượng LogisticRegression, điều chỉnh max_iter nếu cần thiết  \nclassifier.fit(features_train, y_train)  # Huấn luyện mô hình\n\n# Step 6: Make Predictions  \ny_pred = classifier.predict(features_test)  # Dự đoán với dữ liệu kiểm tra\n\n# Step 7: Evaluate the Model  \nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))  # Đánh giá độ chính xác\nprint(classification_report(y_test, y_pred))  # In báo cáo phân loại với các chỉ số chính\n\n# Kết thúc đo thời gian\nnd = time.time()\nprint(\"Thời gian thực thi:\", nd - st)  # In ra thời gian thực thi","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n# Step 7: Evaluate the Model and Compute Confusion Matrix\nconf_matrix = confusion_matrix(y_test, y_pred)  # Define conf_matrix here\nclass_names = ['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc']\nclassA =[0,1,2,3,4]\n# Map integer labels to class names\ncategories = [class_names[label] for label in classA]\n# Figure 1: Confusion Matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n            xticklabels=categories, yticklabels=categories)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.savefig('confusion_Logistic.png')\nplt.show","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Bắt đầu đo thời gian\nst = time.time()\n\n# Step 5: Train an SVM Classifier  \nclassifier = SVC(kernel='rbf')  # Tạo đối tượng SVM, kernel có thể là 'linear', 'poly', 'rbf', hoặc 'sigmoid'\nclassifier.fit(features_train, y_train)  # Huấn luyện mô hình\n\n# Step 6: Make Predictions  \ny_pred = classifier.predict(features_test)  # Dự đoán với dữ liệu kiểm tra\n\n# Step 7: Evaluate the Model  \nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))  # Đánh giá độ chính xác\nprint(classification_report(y_test, y_pred))  # In báo cáo phân loại với các chỉ số chính\n\n# Kết thúc đo thời gian\nnd = time.time()\nprint(\"Thời gian thực thi:\", nd - st)  # In ra thời gian thực thi\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n# Step 7: Evaluate the Model and Compute Confusion Matrix\nconf_matrix = confusion_matrix(y_test, y_pred)  # Define conf_matrix here\nclass_names = ['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc']\nclassA =[0,1,2,3,4]\n# Map integer labels to class names\ncategories = [class_names[label] for label in classA]\n# Figure 1: Confusion Matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n            xticklabels=categories, yticklabels=categories)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.savefig('confusion_SVM.png')\nplt.show","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Trich xuat dac trung su dung inception resnetv2** ","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom PIL import Image, UnidentifiedImageError\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom tqdm import tqdm\nimport warnings\nimport timm  # For Inception-ResNet-v2\nimport time\nimport cv2\nfrom concurrent.futures import ThreadPoolExecutor\n\n# Start timing\nst = time.time()\n\n# Suppress warnings for cleaner output\nwarnings.filterwarnings(\"ignore\")\n\n# Custom Dataset class\nclass ImageDataset(Dataset):\n    def __init__(self, image_paths, labels, label_map):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.label_map = label_map\n        self.preprocess = transforms.Compose([\n            transforms.Resize((299, 299)),  # Inception-ResNet-v2 requires 299x299\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225]),])\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        try:\n            image = Image.open(img_path).convert(\"RGB\")\n            image_tensor = self.preprocess(image)\n            label_idx = self.label_map[label]\n            return image_tensor, label_idx, img_path\n        except (UnidentifiedImageError, Exception) as e:\n            print(f\"Error loading image {img_path}: {e}\")\n            return torch.zeros(3, 299, 299), -1, img_path  # Dummy for invalid image\n\ndef extract_features(\n    image_paths,\n    labels,\n    model_name='inception_resnet_v2',\n    device=None,\n    batch_size=16,\n    num_workers=4,\n    save_features=False,\n    output_dir='features',\n    label_map=None):\n    if device is None:\n        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    \n    num_workers = min(num_workers, os.cpu_count() or 1)\n\n    if len(image_paths) != len(labels):\n        raise ValueError(\"Number of image paths and labels must match.\")\n    if len(image_paths) == 0:\n        print(\"No images provided.\")\n        return np.array([]), np.array([]), []\n\n    try:\n        model = timm.create_model(model_name, pretrained=True)\n    except Exception as e:\n        raise ValueError(f\"Failed to load model {model_name}: {e}\")\n\n    model.eval()\n    model.to(device)\n\n    dataset = ImageDataset(image_paths, labels, label_map=label_map)\n    dataloader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        shuffle=False,\n        pin_memory=(device != 'cpu'))\n\n    features = []\n    extracted_labels = []\n    valid_paths = []\n\n    for batch_tensors, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting features\"):\n        batch_tensors = batch_tensors.to(device)\n        valid_mask = batch_labels != -1\n        if valid_mask.sum() == 0:\n            continue\n\n        with torch.no_grad():\n            batch_features = model.forward_features(batch_tensors[valid_mask])\n            batch_features = torch.nn.functional.adaptive_avg_pool2d(batch_features, (1, 1))\n            batch_features = batch_features.view(batch_features.size(0), -1).cpu().numpy()\n\n        features.append(batch_features)\n        extracted_labels.extend(batch_labels[valid_mask].cpu().numpy())\n        valid_paths.extend([batch_paths[i] for i in range(len(batch_paths)) if valid_mask[i]])\n\n    if not features:\n        print(\"No valid images processed.\")\n        return np.empty((0, model.num_features)), np.array([]), []\n\n    features = np.concatenate(features, axis=0)\n    extracted_labels = np.array(extracted_labels)\n\n    if save_features:\n        os.makedirs(output_dir, exist_ok=True)\n        np.save(os.path.join(output_dir, 'features.npy'), features)\n        np.save(os.path.join(output_dir, 'labels.npy'), extracted_labels)\n        with open(os.path.join(output_dir, 'valid_paths.txt'), 'w') as f:\n            f.write('\\n'.join(valid_paths))\n        print(f\"Features saved to {output_dir}\")\n\n    print(f\"Extracted {features.shape[0]} features.\")\n    return features, extracted_labels, valid_paths\n\n    features = np.concatenate(features, axis=0)\n    extracted_labels = np.array(extracted_labels)\ndef get_image_paths_and_labels(folder_path):\n    image_paths = []\n    labels = []\n    label_map = {}\n    for idx, label_name in enumerate(sorted(os.listdir(folder_path))):\n        label_folder = os.path.join(folder_path, label_name)\n        if os.path.isdir(label_folder):\n            label_map[label_name] = idx\n            for filename in os.listdir(label_folder):\n                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n                    image_paths.append(os.path.join(label_folder, filename))\n                    labels.append(label_name)\n    return image_paths, labels, label_map\n\n# Folder paths\ntrain_folder = \"/kaggle/input/lc25000/lung_colon_image_set/Train and Validation Set\"\ntest_folder = \"/kaggle/input/lc25000/lung_colon_image_set/Test Set\"\n\n# Load image paths and labels\nx_train_paths, y_train, train_label_map = get_image_paths_and_labels(train_folder)\nx_test_paths, y_test, test_label_map = get_image_paths_and_labels(test_folder)\n\n# Confirm device\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")\n\n\n# Extract test features\nprint(\"Extracting features for test set...\")\nxtest_features, y_test_labels, _ = extract_features(\n    x_test_paths,\n    y_test,\n    model_name='inception_resnet_v2',\n    device=device,\n    batch_size=16,\n    num_workers=4,\n    save_features=True,\n    output_dir='test_features',\n    label_map=test_label_map\n)\n# Extract train features\nprint(\"Extracting features for training set...\")\nxtrain_features, y_train_labels, _ = extract_features(\n    x_train_paths,\n    y_train,\n    model_name='inception_resnet_v2',\n    device=device,\n    batch_size=16,\n    num_workers=4,\n    save_features=True,\n    output_dir='train_features',\n    label_map=train_label_map\n)\n\n# Output shapes\nprint(f\"Train features shape: {xtrain_features.shape}\")\nprint(f\"Train labels shape: {y_train_labels.shape}\")\nprint(f\"Test features shape: {xtest_features.shape}\")\nprint(f\"Test labels shape: {y_test_labels.shape}\")\n\n# End timing\nend = time.time()\nprint(f\"Total execution time: {end - st:.2f} seconds\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.neighbors import KernelDensity\nimport numpy as np\nimport time\nst=time.time()\nclass KDE_NaiveBayes:\n    def __init__(self, bandwidth=0.05, default_class=None):\n        self.bandwidth = bandwidth\n        self.kde_models = {}\n        self.classes = None\n        self.priors = None\n        self.default_class = default_class  # Fallback class if no valid prediction\n\n    def fit(self, X, y):\n        self.classes = np.unique(y)\n        self.priors = {}\n        n_samples = len(y)\n\n        # Calculate prior probabilities\n        for c in self.classes:\n            self.priors[c] = np.sum(y == c) / n_samples\n        \n        # Fit KDE for each feature and each class, skip if no samples\n        for c in self.classes:\n            X_c = X[y == c]\n            if X_c.shape[0] == 0:\n                print(f\"Warning: No samples found for class {c}. Skipping KDE fitting.\")\n                self.kde_models[c] = None\n                continue\n            self.kde_models[c] = []\n            for feature_idx in range(X.shape[1]):\n                kde = KernelDensity(bandwidth=self.bandwidth, kernel='gaussian')\n                kde.fit(X_c[:, feature_idx].reshape(-1, 1))\n                self.kde_models[c].append(kde)\n\n    def predict(self, X):\n        n_samples = X.shape[0]\n        log_probs = np.zeros((n_samples, len(self.classes)))\n\n        for idx, c in enumerate(self.classes):\n            log_prior = np.log(self.priors[c]) if self.priors[c] > 0 else -np.inf\n            if self.kde_models[c] is None:\n                log_probs[:, idx] = -np.inf\n                continue\n            log_likelihood = np.zeros(n_samples)\n            for feature_idx, kde in enumerate(self.kde_models[c]):\n                feature_log_prob = kde.score_samples(X[:, feature_idx].reshape(-1, 1))\n                log_likelihood += feature_log_prob\n            log_probs[:, idx] = log_prior+log_likelihood\n        \n        # Check if all probabilities are -inf\n        if np.all(log_probs == -np.inf, axis=1).any():\n            if self.default_class is not None:\n                print(f\"Warning: Some samples have no valid class probabilities. Using default class: {self.default_class}\")\n                y_pred = np.array([self.default_class if np.all(log_probs[i] == -np.inf) else self.classes[np.argmax(log_probs[i])] for i in range(n_samples)])\n            else:\n                raise ValueError(\"No valid predictions possible for some samples; all classes have zero probability. Set a default_class to handle this.\")\n        else:\n            y_pred = self.classes[np.argmax(log_probs, axis=1)]\n        \n        return y_pred\n\n# Example usage\nclassifier = KDE_NaiveBayes(bandwidth=0.05, default_class='Normal')  # Set a default class\nclassifier.fit(xtrain_features, y_train_labels)\ny_pred = classifier.predict(xtest_features)\n\nprint(\"Accuracy:\", accuracy_score(y_test_labels, y_pred))\nprint(classification_report(y_test_labels, y_pred))\nnd=time.time()\nprint(\"Thoi gian\",nd-st)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torchvision import transforms\nfrom transformers import ViTModel, ViTFeatureExtractor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom PIL import Image\nimport os\nimport cv2\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder  # <-- add this\nfrom tensorflow.keras.utils import to_categorical","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nimport time\nst=time.time()\n# Step 5: Train a Naive Bayes Classifier  \nclassifier = GaussianNB()  \nclassifier.fit(xtrain_features, y_train_labels)  # Training the classifier  \n\n# Step 6: Make Predictions  \ny_pred = classifier.predict(xtest_features)  \n\n# Step 7: Evaluate the Model  \nprint(\"Accuracy:\", accuracy_score(y_test_labels, y_pred))  \nprint(classification_report(y_test_labels, y_pred))  \nnd=time.time()\nprint(\"Thoi gian thu thi\", nd-st)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**2. Inception v3 Features**","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom PIL import Image, UnidentifiedImageError\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom tqdm import tqdm\nimport warnings\nimport timm  # For Inception-ResNet-v2\nimport time\nimport cv2\nfrom concurrent.futures import ThreadPoolExecutor\n\n# Start timing\nst = time.time()\n\n# Suppress warnings for cleaner output\nwarnings.filterwarnings(\"ignore\")\n\n# Custom Dataset class\nclass ImageDataset(Dataset):\n    def __init__(self, image_paths, labels, label_map):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.label_map = label_map\n        self.preprocess = transforms.Compose([\n            transforms.Resize((299, 299)),  # Inception-ResNet-v2 requires 299x299\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225]),])\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        try:\n            image = Image.open(img_path).convert(\"RGB\")\n            image_tensor = self.preprocess(image)\n            label_idx = self.label_map[label]\n            return image_tensor, label_idx, img_path\n        except (UnidentifiedImageError, Exception) as e:\n            print(f\"Error loading image {img_path}: {e}\")\n            return torch.zeros(3, 299, 299), -1, img_path  # Dummy for invalid image\n\ndef extract_features(\n    image_paths,\n    labels,\n    model_name='inception_resnet_v2',\n    device=None,\n    batch_size=16,\n    num_workers=4,\n    save_features=False,\n    output_dir='features',\n    label_map=None):\n    if device is None:\n        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    \n    num_workers = min(num_workers, os.cpu_count() or 1)\n\n    if len(image_paths) != len(labels):\n        raise ValueError(\"Number of image paths and labels must match.\")\n    if len(image_paths) == 0:\n        print(\"No images provided.\")\n        return np.array([]), np.array([]), []\n\n    try:\n        model = timm.create_model(model_name, pretrained=True)\n    except Exception as e:\n        raise ValueError(f\"Failed to load model {model_name}: {e}\")\n\n    model.eval()\n    model.to(device)\n\n    dataset = ImageDataset(image_paths, labels, label_map=label_map)\n    dataloader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        shuffle=False,\n        pin_memory=(device != 'cpu'))\n\n    features = []\n    extracted_labels = []\n    valid_paths = []\n\n    for batch_tensors, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting features\"):\n        batch_tensors = batch_tensors.to(device)\n        valid_mask = batch_labels != -1\n        if valid_mask.sum() == 0:\n            continue\n\n        with torch.no_grad():\n            batch_features = model.forward_features(batch_tensors[valid_mask])\n            batch_features = torch.nn.functional.adaptive_avg_pool2d(batch_features, (1, 1))\n            batch_features = batch_features.view(batch_features.size(0), -1).cpu().numpy()\n\n        features.append(batch_features)\n        extracted_labels.extend(batch_labels[valid_mask].cpu().numpy())\n        valid_paths.extend([batch_paths[i] for i in range(len(batch_paths)) if valid_mask[i]])\n\n    if not features:\n        print(\"No valid images processed.\")\n        return np.empty((0, model.num_features)), np.array([]), []\n\n    features = np.concatenate(features, axis=0)\n    extracted_labels = np.array(extracted_labels)\n\n    if save_features:\n        os.makedirs(output_dir, exist_ok=True)\n        np.save(os.path.join(output_dir, 'features.npy'), features)\n        np.save(os.path.join(output_dir, 'labels.npy'), extracted_labels)\n        with open(os.path.join(output_dir, 'valid_paths.txt'), 'w') as f:\n            f.write('\\n'.join(valid_paths))\n        print(f\"Features saved to {output_dir}\")\n\n    print(f\"Extracted {features.shape[0]} features.\")\n    return features, extracted_labels, valid_paths\n\n    features = np.concatenate(features, axis=0)\n    extracted_labels = np.array(extracted_labels)\ndef get_image_paths_and_labels(folder_path):\n    image_paths = []\n    labels = []\n    label_map = {}\n    for idx, label_name in enumerate(sorted(os.listdir(folder_path))):\n        label_folder = os.path.join(folder_path, label_name)\n        if os.path.isdir(label_folder):\n            label_map[label_name] = idx\n            for filename in os.listdir(label_folder):\n                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n                    image_paths.append(os.path.join(label_folder, filename))\n                    labels.append(label_name)\n    return image_paths, labels, label_map\n\n# Folder paths\ntrain_folder = \"/kaggle/input/lc25000/lung_colon_image_set/Train and Validation Set\"\ntest_folder = \"/kaggle/input/lc25000/lung_colon_image_set/Test Set\"\n\n# Load image paths and labels\nx_train_paths, y_train, train_label_map = get_image_paths_and_labels(train_folder)\nx_test_paths, y_test, test_label_map = get_image_paths_and_labels(test_folder)\n\n# Confirm device\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")\n\n\n# Extract test features\nprint(\"Extracting features for test set...\")\nxtest_features, y_test_labels, _ = extract_features(\n    x_test_paths,\n    y_test,\n    model_name='inception_v3',\n    device=device,\n    batch_size=16,\n    num_workers=4,\n    save_features=True,\n    output_dir='test_features',\n    label_map=test_label_map\n)\n# Extract train features\nprint(\"Extracting features for training set...\")\nxtrain_features, y_train_labels, _ = extract_features(\n    x_train_paths,\n    y_train,\n    model_name='inception_v3',\n    device=device,\n    batch_size=16,\n    num_workers=4,\n    save_features=True,\n    output_dir='train_features',\n    label_map=train_label_map\n)\n\n# Output shapes\nprint(f\"Train features shape: {xtrain_features.shape}\")\nprint(f\"Train labels shape: {y_train_labels.shape}\")\nprint(f\"Test features shape: {xtest_features.shape}\")\nprint(f\"Test labels shape: {y_test_labels.shape}\")\n\n# End timing\nend = time.time()\nprint(f\"Total execution time: {end - st:.2f} seconds\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nimport time\nst=time.time()\n# Step 5: Train a Naive Bayes Classifier  \nclassifier = GaussianNB()  \nclassifier.fit(xtrain_features, y_train_labels)  # Training the classifier  \n\n# Step 6: Make Predictions  \ny_pred = classifier.predict(xtest_features)  \n\n# Step 7: Evaluate the Model  \nprint(\"Accuracy:\", accuracy_score(y_test_labels, y_pred))  \nprint(classification_report(y_test_labels, y_pred))  \nnd=time.time()\nprint(\"Thoi gian thu thi\", nd-st)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from cuml.neighbors import KernelDensity as cuKDE  # GPU version\nimport cupy as cp  # GPU array (like numpy)\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, classification_report\nimport time\n\nclass KDE_NaiveBayes_GPU:\n    def __init__(self, bandwidth=0.05, default_class=None):\n        self.bandwidth = bandwidth\n        self.kde_models = {}\n        self.classes = None\n        self.priors = None\n        self.default_class = default_class\n\n    def fit(self, X, y):\n        X = cp.asarray(X)  # move to GPU\n        y = cp.asarray(y)\n        self.classes = cp.unique(y)\n        self.priors = {}\n        n_samples = len(y)\n\n        for c in self.classes:\n            class_mask = (y == c)\n            self.priors[c.item()] = cp.sum(class_mask).item() / n_samples\n            X_c = X[class_mask]\n            if X_c.shape[0] == 0:\n                print(f\"Warning: No samples for class {c}. Skipping KDE.\")\n                self.kde_models[c.item()] = None\n                continue\n            self.kde_models[c.item()] = []\n            for feature_idx in range(X.shape[1]):\n                kde = cuKDE(kernel='gaussian', bandwidth=self.bandwidth)\n                kde.fit(X_c[:, feature_idx])\n                self.kde_models[c.item()].append(kde)\n\n    def predict(self, X):\n        X = cp.asarray(X)\n        n_samples = X.shape[0]\n        log_probs = cp.zeros((n_samples, len(self.classes)))\n\n        for idx, c in enumerate(self.classes):\n            class_value = c.item()\n            log_prior = cp.log(self.priors[class_value]) if self.priors[class_value] > 0 else -cp.inf\n            if self.kde_models[class_value] is None:\n                log_probs[:, idx] = -cp.inf\n                continue\n            log_likelihood = cp.zeros(n_samples)\n            for feature_idx, kde in enumerate(self.kde_models[class_value]):\n                feature_log_prob = kde.score_samples(X[:, feature_idx])\n                log_likelihood += feature_log_prob\n            log_probs[:, idx] = log_prior + log_likelihood\n\n        y_pred = []\n        for i in range(n_samples):\n            if cp.all(log_probs[i] == -cp.inf):\n                if self.default_class is not None:\n                    print(f\"Warning: Sample {i} has no valid probabilities. Using default class.\")\n                    y_pred.append(self.default_class)\n                else:\n                    raise ValueError(f\"Sample {i}: No valid prediction and no default_class provided.\")\n            else:\n                pred_class = self.classes[cp.argmax(log_probs[i])].item()\n                y_pred.append(pred_class)\n\n        return np.array(y_pred)  # back to CPU\n\n# ======================\n# Example usage\n# ======================\n# Replace the following with your actual data:\n# xtrain_features, xtest_features = shape (n_samples, n_features)\n# y_train_labels, y_test_labels = shape (n_samples,)\n\n# You must have your xtrain_features, y_train_labels, xtest_features, y_test_labels defined\n# Example placeholders (remove or replace with real data):\n# xtrain_features = np.random.rand(100, 10)\n# y_train_labels = np.random.choice(['Normal', 'Anomaly'], 100)\n# xtest_features = np.random.rand(20, 10)\n# y_test_labels = np.random.choice(['Normal', 'Anomaly'], 20)\n\nst = time.time()\nclassifier = KDE_NaiveBayes_GPU(bandwidth=0.05, default_class='Normal')\nclassifier.fit(xtrain_features, y_train_labels)\ny_pred = classifier.predict(xtest_features)\n\nprint(\"Accuracy:\", accuracy_score(y_test_labels, y_pred))\nprint(classification_report(y_test_labels, y_pred))\nprint(\"Thời gian:\", time.time() - st)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**VGG16**","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom PIL import Image, UnidentifiedImageError\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models, transforms\nfrom tqdm import tqdm\nimport warnings\nimport time\nimport cv2\nfrom concurrent.futures import ThreadPoolExecutor\n\n# Start timing\nst = time.time()\nwarnings.filterwarnings(\"ignore\")\n\nclass ImageDataset(Dataset):\n    def __init__(self, image_paths, labels, label_map):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.label_map = label_map\n        self.preprocess = transforms.Compose([\n            transforms.Resize((224, 224)),  # VGG16 uses 224x224\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225]),\n        ])\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        try:\n            image = Image.open(img_path).convert(\"RGB\")\n            image_tensor = self.preprocess(image)\n            label_idx = self.label_map[label]\n            return image_tensor, label_idx, img_path\n        except (UnidentifiedImageError, Exception) as e:\n            print(f\"Error loading image {img_path}: {e}\")\n            return torch.zeros(3, 224, 224), -1, img_path  # Dummy for invalid image\n\ndef extract_features(image_paths, labels, device=None,\n                     batch_size=16, num_workers=4, save_features=False,\n                     output_dir='features', label_map=None):\n\n    if device is None:\n        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n    if len(image_paths) != len(labels):\n        raise ValueError(\"Number of image paths and labels must match.\")\n    if len(image_paths) == 0:\n        print(\"No images provided.\")\n        return np.array([]), np.array([]), []\n\n    # Load pretrained VGG16\n    model = models.vgg16(pretrained=True)\n    model = model.features  # Use only the convolutional base\n    model.eval().to(device)\n\n    dataset = ImageDataset(image_paths, labels, label_map=label_map)\n    dataloader = DataLoader(dataset, batch_size=batch_size,\n                            num_workers=num_workers, shuffle=False,\n                            pin_memory=(device != 'cpu'))\n\n    features, extracted_labels, valid_paths = [], [], []\n\n    for batch_tensors, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting features\"):\n        batch_tensors = batch_tensors.to(device)\n        valid_mask = batch_labels != -1\n        if valid_mask.sum() == 0:\n            continue\n\n        with torch.no_grad():\n            # Pass through VGG16 convolutional layers\n            conv_feats = model(batch_tensors[valid_mask])\n            # Apply global average pooling to get [B, 512]\n            batch_feat = torch.nn.functional.adaptive_avg_pool2d(conv_feats, (1, 1)).view(conv_feats.size(0), -1)\n            batch_feat = batch_feat.cpu().numpy()\n\n        features.append(batch_feat)\n        extracted_labels.extend(batch_labels[valid_mask].cpu().numpy())\n        valid_paths.extend([batch_paths[i] for i in range(len(batch_paths)) if valid_mask[i]])\n\n    if not features:\n        print(\"No valid images processed.\")\n        return np.empty((0, 512)), np.array([]), []\n\n    features = np.concatenate(features, axis=0)\n    extracted_labels = np.array(extracted_labels)\n\n    if save_features:\n        os.makedirs(output_dir, exist_ok=True)\n        np.save(os.path.join(output_dir, 'features.npy'), features)\n        np.save(os.path.join(output_dir, 'labels.npy'), extracted_labels)\n        with open(os.path.join(output_dir, 'valid_paths.txt'), 'w') as f:\n            f.write('\\n'.join(valid_paths))\n        print(f\"Features saved to {output_dir}\")\n\n    print(f\"Extracted {features.shape[0]} features.\")\n    return features, extracted_labels, valid_paths\n\ndef get_image_paths_and_labels(folder_path):\n    image_paths, labels, label_map = [], [], {}\n    for idx, label_name in enumerate(sorted(os.listdir(folder_path))):\n        label_folder = os.path.join(folder_path, label_name)\n        if os.path.isdir(label_folder):\n            label_map[label_name] = idx\n            for filename in os.listdir(label_folder):\n                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n                    image_paths.append(os.path.join(label_folder, filename))\n                    labels.append(label_name)\n    return image_paths, labels, label_map\n\n# Folder paths\ntrain_folder = \"/kaggle/input/lc25000/lung_colon_image_set/Train and Validation Set\"\ntest_folder = \"/kaggle/input/lc25000/lung_colon_image_set/Test Set\"\n\n# Load image paths and labels\nx_train_paths, y_train, train_label_map = get_image_paths_and_labels(train_folder)\nx_test_paths, y_test, test_label_map = get_image_paths_and_labels(test_folder)\n\n# Confirm device\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")\n\n# Extract test features\nprint(\"Extracting features for test set...\")\nxtest_features, y_test_labels, _ = extract_features(\n    x_test_paths, y_test, device=device, batch_size=16,\n    num_workers=4, save_features=True,\n    output_dir='test_features', label_map=test_label_map\n)\n\n# Extract train features\nprint(\"Extracting features for training set...\")\nxtrain_features, y_train_labels, _ = extract_features(\n    x_train_paths, y_train, device=device, batch_size=16,\n    num_workers=4, save_features=True,\n    output_dir='train_features', label_map=train_label_map\n)\n\n# Output shapes\nprint(f\"Train features shape: {xtrain_features.shape}\")\nprint(f\"Train labels shape: {y_train_labels.shape}\")\nprint(f\"Test features shape: {xtest_features.shape}\")\nprint(f\"Test labels shape: {y_test_labels.shape}\")\n\n# End timing\nend = time.time()\nprint(f\"Total execution time: {end - st:.2f} seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:06:37.808125Z","iopub.execute_input":"2025-05-07T02:06:37.808758Z","iopub.status.idle":"2025-05-07T02:09:08.035402Z","shell.execute_reply.started":"2025-05-07T02:06:37.808725Z","shell.execute_reply":"2025-05-07T02:09:08.034245Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nExtracting features for test set...\n","output_type":"stream"},{"name":"stderr","text":"Extracting features: 100%|██████████| 157/157 [00:15<00:00, 10.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Features saved to test_features\nExtracted 2499 features.\nExtracting features for training set...\n","output_type":"stream"},{"name":"stderr","text":"Extracting features: 100%|██████████| 1407/1407 [02:11<00:00, 10.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Features saved to train_features\nExtracted 22501 features.\nTrain features shape: (22501, 512)\nTrain labels shape: (22501,)\nTest features shape: (2499, 512)\nTest labels shape: (2499,)\nTotal execution time: 150.21 seconds\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nimport time\nst=time.time()\n# Step 5: Train a Naive Bayes Classifier  \nclassifier = GaussianNB()  \nclassifier.fit(xtrain_features, y_train_labels)  # Training the classifier  \n\n# Step 6: Make Predictions  \ny_pred = classifier.predict(xtest_features)  \n\n# Step 7: Evaluate the Model  \nprint(\"Accuracy:\", accuracy_score(y_test_labels, y_pred))  \nprint(classification_report(y_test_labels, y_pred))  \nnd=time.time()\nprint(\"Thoi gian thu thi\", nd-st)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:10:00.706612Z","iopub.execute_input":"2025-05-07T02:10:00.706959Z","iopub.status.idle":"2025-05-07T02:10:00.838155Z","shell.execute_reply.started":"2025-05-07T02:10:00.706932Z","shell.execute_reply":"2025-05-07T02:10:00.837191Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8803521408563425\n              precision    recall  f1-score   support\n\n           0       0.87      0.92      0.89       500\n           1       0.97      0.91      0.94       500\n           2       0.83      0.71      0.76       500\n           3       0.98      0.99      0.98       500\n           4       0.76      0.88      0.82       499\n\n    accuracy                           0.88      2499\n   macro avg       0.88      0.88      0.88      2499\nweighted avg       0.88      0.88      0.88      2499\n\nThoi gian thu thi 0.1259174346923828\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from cuml.neighbors import KernelDensity as cuKDE  # GPU version\nimport cupy as cp  # GPU array (like numpy)\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, classification_report\nimport time\n\nclass KDE_NaiveBayes_GPU:\n    def __init__(self, bandwidth=0.05, default_class=None):\n        self.bandwidth = bandwidth\n        self.kde_models = {}\n        self.classes = None\n        self.priors = None\n        self.default_class = default_class\n\n    def fit(self, X, y):\n        X = cp.asarray(X)  # move to GPU\n        y = cp.asarray(y)\n        self.classes = cp.unique(y)\n        self.priors = {}\n        n_samples = len(y)\n\n        for c in self.classes:\n            class_mask = (y == c)\n            self.priors[c.item()] = cp.sum(class_mask).item() / n_samples\n            X_c = X[class_mask]\n            if X_c.shape[0] == 0:\n                print(f\"Warning: No samples for class {c}. Skipping KDE.\")\n                self.kde_models[c.item()] = None\n                continue\n            self.kde_models[c.item()] = []\n            for feature_idx in range(X.shape[1]):\n                kde = cuKDE(kernel='gaussian', bandwidth=self.bandwidth)\n                kde.fit(X_c[:, feature_idx])\n                self.kde_models[c.item()].append(kde)\n\n    def predict(self, X):\n        X = cp.asarray(X)\n        n_samples = X.shape[0]\n        log_probs = cp.zeros((n_samples, len(self.classes)))\n\n        for idx, c in enumerate(self.classes):\n            class_value = c.item()\n            log_prior = cp.log(self.priors[class_value]) if self.priors[class_value] > 0 else -cp.inf\n            if self.kde_models[class_value] is None:\n                log_probs[:, idx] = -cp.inf\n                continue\n            log_likelihood = cp.zeros(n_samples)\n            for feature_idx, kde in enumerate(self.kde_models[class_value]):\n                feature_log_prob = kde.score_samples(X[:, feature_idx])\n                log_likelihood += feature_log_prob\n            log_probs[:, idx] = log_prior + log_likelihood\n\n        y_pred = []\n        for i in range(n_samples):\n            if cp.all(log_probs[i] == -cp.inf):\n                if self.default_class is not None:\n                    print(f\"Warning: Sample {i} has no valid probabilities. Using default class.\")\n                    y_pred.append(self.default_class)\n                else:\n                    raise ValueError(f\"Sample {i}: No valid prediction and no default_class provided.\")\n            else:\n                pred_class = self.classes[cp.argmax(log_probs[i])].item()\n                y_pred.append(pred_class)\n\n        return np.array(y_pred)  # back to CPU\n\n# ======================\n# Example usage\n# ======================\n# Replace the following with your actual data:\n# xtrain_features, xtest_features = shape (n_samples, n_features)\n# y_train_labels, y_test_labels = shape (n_samples,)\n\n# You must have your xtrain_features, y_train_labels, xtest_features, y_test_labels defined\n# Example placeholders (remove or replace with real data):\n# xtrain_features = np.random.rand(100, 10)\n# y_train_labels = np.random.choice(['Normal', 'Anomaly'], 100)\n# xtest_features = np.random.rand(20, 10)\n# y_test_labels = np.random.choice(['Normal', 'Anomaly'], 20)\n\nst = time.time()\nclassifier = KDE_NaiveBayes_GPU(bandwidth=0.05, default_class='Normal')\nclassifier.fit(xtrain_features, y_train_labels)\ny_pred = classifier.predict(xtest_features)\n\nprint(\"Accuracy:\", accuracy_score(y_test_labels, y_pred))\nprint(classification_report(y_test_labels, y_pred))\nprint(\"Thời gian:\", time.time() - st)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:11:01.389651Z","iopub.execute_input":"2025-05-07T02:11:01.389985Z","iopub.status.idle":"2025-05-07T02:11:34.954610Z","shell.execute_reply.started":"2025-05-07T02:11:01.389961Z","shell.execute_reply":"2025-05-07T02:11:34.953813Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.923969587835134\n              precision    recall  f1-score   support\n\n           0       0.94      0.94      0.94       500\n           1       0.98      0.92      0.95       500\n           2       0.87      0.87      0.87       500\n           3       0.98      0.99      0.99       500\n           4       0.85      0.91      0.88       499\n\n    accuracy                           0.92      2499\n   macro avg       0.93      0.92      0.92      2499\nweighted avg       0.93      0.92      0.92      2499\n\nThời gian: 30.607917308807373\n","output_type":"stream"}],"execution_count":6}]}