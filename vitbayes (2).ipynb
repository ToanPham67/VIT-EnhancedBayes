{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"4933fd4cdb6745bc817080144abe2183":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8576e8c1aeee485eb193381ceb1b8650","IPY_MODEL_9c2d8f4ed9a94d31a4fc965e63771c2f","IPY_MODEL_bdb078ad38924a0686985656df811a27"],"layout":"IPY_MODEL_251d7887b5d74db69319e5a5777dc825"}},"8576e8c1aeee485eb193381ceb1b8650":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0edd6fa22a2e48fe9e369f56cf9d7e8d","placeholder":"​","style":"IPY_MODEL_7726a612b7814f958267f5c60f4cbe3b","value":"preprocessor_config.json: 100%"}},"9c2d8f4ed9a94d31a4fc965e63771c2f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2ad29fd60d044e7b162d78f55249a87","max":160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53a2f9d1593f460a91d1dc4a53a6f4d6","value":160}},"bdb078ad38924a0686985656df811a27":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f9f0764c89a45baa575de72c61327f0","placeholder":"​","style":"IPY_MODEL_5bb29da75a7a4d7197866197cebe718b","value":" 160/160 [00:00&lt;00:00, 9.82kB/s]"}},"251d7887b5d74db69319e5a5777dc825":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0edd6fa22a2e48fe9e369f56cf9d7e8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7726a612b7814f958267f5c60f4cbe3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2ad29fd60d044e7b162d78f55249a87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53a2f9d1593f460a91d1dc4a53a6f4d6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f9f0764c89a45baa575de72c61327f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bb29da75a7a4d7197866197cebe718b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e031edab71c347e4b6938a53658a174b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e3a3f4581be46c89ec723d76f8cbbeb","IPY_MODEL_14d2d62b1eca4710a436aec1a3fb815a","IPY_MODEL_32a25e85ec0844558d640642fc0e8358"],"layout":"IPY_MODEL_4ea74f3b84fe4770b57472c52a3cd7d9"}},"4e3a3f4581be46c89ec723d76f8cbbeb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c1ecd36d813465e802cbd6b8570703a","placeholder":"​","style":"IPY_MODEL_7d801bd37b3a4986b4d61616d30f204a","value":"config.json: 100%"}},"14d2d62b1eca4710a436aec1a3fb815a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_be5027b7bac54cdc81744345848dc3a1","max":69665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b9e8a2cf980d4051a24366054734b492","value":69665}},"32a25e85ec0844558d640642fc0e8358":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f9e91555cb34fe9a967cbcb0fe583fc","placeholder":"​","style":"IPY_MODEL_82e89b03fa334d9687b11a9de88f537c","value":" 69.7k/69.7k [00:00&lt;00:00, 3.42MB/s]"}},"4ea74f3b84fe4770b57472c52a3cd7d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c1ecd36d813465e802cbd6b8570703a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d801bd37b3a4986b4d61616d30f204a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be5027b7bac54cdc81744345848dc3a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9e8a2cf980d4051a24366054734b492":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5f9e91555cb34fe9a967cbcb0fe583fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82e89b03fa334d9687b11a9de88f537c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed58aa3a1893453289347ee60062bc29":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_88051078ab6643cd8702f48762caf40c","IPY_MODEL_e877f6842e13466bbfd56e5df7af7436","IPY_MODEL_87bf1a1fabdb4a27832ff6c99dac74a7"],"layout":"IPY_MODEL_a761b606f1284b7dace7cfd82021342a"}},"88051078ab6643cd8702f48762caf40c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfcf0c4169744e0597c0c7634fa9bcfe","placeholder":"​","style":"IPY_MODEL_02bfdbae26984ffa92a790f003a003bd","value":"model.safetensors: 100%"}},"e877f6842e13466bbfd56e5df7af7436":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_adde0737c99947c79386ea02991c35f8","max":346293852,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ebf355360c1145d58a4b8c88ae0ef611","value":346293852}},"87bf1a1fabdb4a27832ff6c99dac74a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e5677f1660b4ceaa699c05b9bfd7977","placeholder":"​","style":"IPY_MODEL_5edf70d96ac74302a0e6f2095ab732e8","value":" 346M/346M [00:06&lt;00:00, 43.2MB/s]"}},"a761b606f1284b7dace7cfd82021342a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfcf0c4169744e0597c0c7634fa9bcfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02bfdbae26984ffa92a790f003a003bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"adde0737c99947c79386ea02991c35f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebf355360c1145d58a4b8c88ae0ef611":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8e5677f1660b4ceaa699c05b9bfd7977":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5edf70d96ac74302a0e6f2095ab732e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11187168,"sourceType":"datasetVersion","datasetId":6983618},{"sourceId":11187390,"sourceType":"datasetVersion","datasetId":6983760},{"sourceId":11195627,"sourceType":"datasetVersion","datasetId":6989594},{"sourceId":11241896,"sourceType":"datasetVersion","datasetId":7023781}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torchvision import transforms\nfrom transformers import ViTModel, ViTFeatureExtractor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom PIL import Image","metadata":{"id":"Vom_JY1xCtku","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:41:21.271953Z","iopub.execute_input":"2025-04-05T12:41:21.272201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Load the Pre-trained Vision Transformer Model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Load ViT model and feature extractor\nfeature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\nmodel = ViTModel.from_pretrained('google/vit-base-patch16-224').to(device)\nmodel.eval()  # Set the model to evaluation mode","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["4933fd4cdb6745bc817080144abe2183","8576e8c1aeee485eb193381ceb1b8650","9c2d8f4ed9a94d31a4fc965e63771c2f","bdb078ad38924a0686985656df811a27","251d7887b5d74db69319e5a5777dc825","0edd6fa22a2e48fe9e369f56cf9d7e8d","7726a612b7814f958267f5c60f4cbe3b","c2ad29fd60d044e7b162d78f55249a87","53a2f9d1593f460a91d1dc4a53a6f4d6","7f9f0764c89a45baa575de72c61327f0","5bb29da75a7a4d7197866197cebe718b","e031edab71c347e4b6938a53658a174b","4e3a3f4581be46c89ec723d76f8cbbeb","14d2d62b1eca4710a436aec1a3fb815a","32a25e85ec0844558d640642fc0e8358","4ea74f3b84fe4770b57472c52a3cd7d9","4c1ecd36d813465e802cbd6b8570703a","7d801bd37b3a4986b4d61616d30f204a","be5027b7bac54cdc81744345848dc3a1","b9e8a2cf980d4051a24366054734b492","5f9e91555cb34fe9a967cbcb0fe583fc","82e89b03fa334d9687b11a9de88f537c","ed58aa3a1893453289347ee60062bc29","88051078ab6643cd8702f48762caf40c","e877f6842e13466bbfd56e5df7af7436","87bf1a1fabdb4a27832ff6c99dac74a7","a761b606f1284b7dace7cfd82021342a","bfcf0c4169744e0597c0c7634fa9bcfe","02bfdbae26984ffa92a790f003a003bd","adde0737c99947c79386ea02991c35f8","ebf355360c1145d58a4b8c88ae0ef611","8e5677f1660b4ceaa699c05b9bfd7977","5edf70d96ac74302a0e6f2095ab732e8"]},"id":"gQXhtbW2DdQg","outputId":"5f9a5d26-978f-4cc8-bf31-64ec4afab146","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip3 install torchinfo\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import ViTModel\nfrom torchinfo import summary\n\n# Load the pre-trained Vision Transformer (ViT) model\nmodel = ViTModel.from_pretrained('google/vit-base-patch16-224')\n\n# Get the model summary\nsummary(model, input_size=(1, 3, 224, 224))  # Batch size of 1, RGB channels, 224x224 image\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2: Load Images and Prepare Labels  \nimage_folder = '/kaggle/input/skindatav2/CancerSkin'  # Update with your image folder path  \nimage_files = os.listdir(image_folder)  \nlabels = [file.split('_')[0] for file in image_files]  # Assume label is part of the filename  \nlabels = ['Normal', 'Cancer']\nlabels\n# Step 3: Train-Test Split  \n#X_train_paths, X_test_paths, y_train, y_test = train_test_split(image_paths, labels, test_size=0.2, random_state=42)  \n# Example directory structure  \nbase_dir = '/kaggle/input/skindatav2/CancerSkin'  # Change this to your dataset path  \ncategories = ['Normal', 'Cancer'] # Define your categories  \n\nimage_paths = []  \nlabels = []  \n\n# Collect all paths and corresponding labels  \nfor category in categories:  \n    category_path = os.path.join(base_dir, category)  \n    for filename in os.listdir(category_path):  \n        if filename.endswith('.jpg') or filename.endswith('.png'):  # Check for image files  \n            image_paths.append(os.path.join(category_path, filename))  \n            labels.append(category)  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create train-test split  \nX_train, X_test, y_train, y_test = train_test_split(  \n    image_paths,  \n    labels,  \n    test_size=0.2,  # 20% of data will be used as test set  \n    random_state=42,  # For reproducibility \n) \nfrom sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(y_train)  # Encoding train labels\ny_test = label_encoder.transform(y_test)  # Encoding test labels\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Define categories (class labels)\ncategories = sorted(set(y_train) | set(y_test))  # Get unique class labels\n\n# Count occurrences of each class\ntrain_counts = [np.count_nonzero(y_train == cls) for cls in categories]\ntest_counts = [np.count_nonzero(y_test == cls) for cls in categories]\n\n# Plotting\nfig, ax = plt.subplots(figsize=(10, 6))\nbar_width = 0.35\nindex = np.arange(len(categories))\n\n# Create bars\ntrain_bars = plt.bar(index, train_counts, bar_width, label='Train', color='skyblue')\ntest_bars = plt.bar(index + bar_width, test_counts, bar_width, label='Test', color='salmon')\n\n# Add numbers on top of bars\nfor bars in [train_bars, test_bars]:\n    for bar in bars:\n        height = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width() / 2, height, f'{int(height)}',\n                 ha='center', va='bottom', fontsize=10, fontweight='bold', color='black')\ncategories = ['Normal', 'Cancer']\n# Formatting the plot\nplt.xlabel('Categories', fontsize=12, fontweight='bold')  # ✅ Label for x-axis\nplt.ylabel('Number of Samples', fontsize=12, fontweight='bold')\n#plt.title('Train-Test Split Distribution', fontsize=14, fontweight='bold')\nplt.xticks(index + bar_width / 2, categories, rotation=30, ha=\"right\", fontsize=10)  # ✅ Class names added\nplt.legend()\nplt.grid(axis='y', linestyle='-', alpha=0.7)  # Add horizontal grid lines for better readability\n\nplt.savefig('train_test.png', dpi=300, bbox_inches='tight')  # Save as PNG with high resolution\n\n# Display the plot\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**1. Trích xuất đặc trưng của ảnh - Mỗi ảnh sẽ được đại diện bởi 768 giá trị. ** ","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nfrom PIL import Image, UnidentifiedImageError\n\ndef extract_features(image_paths, feature_extractor, model, device):\n    features = []\n    \n    for img_path in image_paths:\n        if os.path.isfile(img_path):\n            try:\n                # Load image and preprocess\n                image = Image.open(img_path).convert(\"RGB\")\n                inputs = feature_extractor(images=image, return_tensors=\"pt\").to(device)\n\n                # Extract features using Transformer model\n                with torch.no_grad():\n                    outputs = model(**inputs)\n\n                # Extract CLS token feature vector\n                cls_token_feature = outputs.last_hidden_state[:, 0, :]  # CLS token representation\n\n                # Convert to NumPy array\n                features.append(cls_token_feature.cpu().numpy().flatten())\n\n            except UnidentifiedImageError:\n                print(f\"Warning: Unable to identify image file {img_path}. Skipping.\")\n            except Exception as e:\n                print(f\"Error loading image {img_path}: {e}\")\n        else:\n            print(f\"Warning: {img_path} is not a valid file.\")\n\n    return np.array(features)","metadata":{"id":"4EY8X7eiDh89","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_image(img_path):\n    \"\"\"Process a single image and extract features.\"\"\"\n    if not os.path.isfile(img_path):\n        print(f\"Warning: {img_path} is not a valid file.\")\n        return None\n    \n    try:\n        # Load and preprocess image\n        image = Image.open(img_path).convert(\"RGB\")  # Ensure 3-channel format\n\n        # Extract features\n        inputs = feature_extractor(images=image, return_tensors=\"pt\").to(device)\n        with torch.no_grad():\n            outputs = model(**inputs)\n        \n        # Average pooling over token dimension\n        feature_vector = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n        return feature_vector.flatten()\n\n    except UnidentifiedImageError:\n        print(f\"Warning: Unable to identify image file {img_path}. Skipping.\")\n    except Exception as e:\n        print(f\"Error processing {img_path}: {e}\")\n\n    return None  # Return None for failed cases\n\ndef extract_features(image_paths, num_workers=4):\n    \"\"\"Parallel feature extraction.\"\"\"\n    features = []\n    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n        results = list(executor.map(process_image, image_paths))\n\n    # Remove None values (failed images) and convert to NumPy array\n    features = np.array([res for res in results if res is not None])\n    return features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nstart=time.time()\nfrom concurrent.futures import ThreadPoolExecutor\nTrain_features = extract_features(X_train, num_workers=4)  # Adjust workers based on CPU cores\nprint(f\"Extracted Features Shape: {Train_features.shape}\") \nend=time.time()\nprint('Thoi gian thu thi',end-start)","metadata":{"id":"7BQZVUv3DsYU","colab":{"base_uri":"https://localhost:8080/","height":408},"outputId":"0da60975-7c83-4414-d9ca-1e35516f7698","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Lưu vào file Excel\ndf = pd.DataFrame(Train_features)  # Chuyển thành DataFrame\ndf.to_excel(\"Train_features.xlsx\", index=False)  # Lưu vào tệp Excel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nstart=time.time()\nfrom concurrent.futures import ThreadPoolExecutor\nTest_features = extract_features(X_test, num_workers=4)  # Adjust workers based on CPU cores\nprint(f\"Extracted Features Shape: {Test_features.shape}\") \nend=time.time()\nprint('Thoi gian thu thi',end-start)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AI6eKFuicOX8","outputId":"bcc5a922-5d2e-45d3-c9f5-fbe3df2763bd","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Lưu vào file Excel\ndf2 = pd.DataFrame(Test_features)  # Chuyển thành DataFrame\ndf2.to_excel(\"Test_features.xlsx\", index=False)  # Lưu vào tệp Excel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**2. Phân loại: Phân pháp Naive bayes nâng cao**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.neighbors import KernelDensity\nimport numpy as np\nimport time\nst=time.time()\nclass KDE_NaiveBayes:\n    def __init__(self, bandwidth=0.05, default_class=None):\n        self.bandwidth = bandwidth\n        self.kde_models = {}\n        self.classes = None\n        self.priors = None\n        self.default_class = default_class  # Fallback class if no valid prediction\n\n    def fit(self, X, y):\n        self.classes = np.unique(y)\n        self.priors = {}\n        n_samples = len(y)\n\n        # Calculate prior probabilities\n        for c in self.classes:\n            self.priors[c] = np.sum(y == c) / n_samples\n        \n        # Fit KDE for each feature and each class, skip if no samples\n        for c in self.classes:\n            X_c = X[y == c]\n            if X_c.shape[0] == 0:\n                print(f\"Warning: No samples found for class {c}. Skipping KDE fitting.\")\n                self.kde_models[c] = None\n                continue\n            self.kde_models[c] = []\n            for feature_idx in range(X.shape[1]):\n                kde = KernelDensity(bandwidth=self.bandwidth, kernel='gaussian')\n                kde.fit(X_c[:, feature_idx].reshape(-1, 1))\n                self.kde_models[c].append(kde)\n\n    def predict(self, X):\n        n_samples = X.shape[0]\n        log_probs = np.zeros((n_samples, len(self.classes)))\n\n        for idx, c in enumerate(self.classes):\n            log_prior = np.log(self.priors[c]) if self.priors[c] > 0 else -np.inf\n            if self.kde_models[c] is None:\n                log_probs[:, idx] = -np.inf\n                continue\n            log_likelihood = np.zeros(n_samples)\n            for feature_idx, kde in enumerate(self.kde_models[c]):\n                feature_log_prob = kde.score_samples(X[:, feature_idx].reshape(-1, 1))\n                log_likelihood += feature_log_prob\n            log_probs[:, idx] = log_prior+log_likelihood\n        \n        # Check if all probabilities are -inf\n        if np.all(log_probs == -np.inf, axis=1).any():\n            if self.default_class is not None:\n                print(f\"Warning: Some samples have no valid class probabilities. Using default class: {self.default_class}\")\n                y_pred = np.array([self.default_class if np.all(log_probs[i] == -np.inf) else self.classes[np.argmax(log_probs[i])] for i in range(n_samples)])\n            else:\n                raise ValueError(\"No valid predictions possible for some samples; all classes have zero probability. Set a default_class to handle this.\")\n        else:\n            y_pred = self.classes[np.argmax(log_probs, axis=1)]\n        \n        return y_pred\n\n# Example usage\nclassifier = KDE_NaiveBayes(bandwidth=0.09, default_class='Normal')  # Set a default class\nclassifier.fit(Train_features, y_train)\ny_pred = classifier.predict(Test_features)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nnd=time.time()\nprint(\"Thoi gian\",nd-st)\n","metadata":{"id":"Dbe1OxaqhizE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Huấn luyện 200, dự đoán là 50 (Test). kết quả dự đoạn:  Ảnh 50 thuộc nhóm 1, Ảnh 51 thuộc vào nhóm 1. Ảnh 52 thuộc vào nhóm 2.(sai).\n\nACC = Tổng số ảnh đúng/ tổng số ảnh test. \nACC= 49/50=0.98 = 98% Độ chính xác.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n# Step 7: Evaluate the Model and Compute Confusion Matrix\nconf_matrix = confusion_matrix(y_test, y_pred)  # Define conf_matrix here\n\n# Figure 1: Confusion Matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n            xticklabels=categories, yticklabels=categories)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.savefig('confusion_matrix.png')\nplt.show\n# plt.close()\n# print(\"Confusion matrix figure saved as 'confusion_matrix.png'.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_kde(classifier, feature_idx, X_train, y_train):\n    x_range = np.linspace(X_train[:, feature_idx].min(), X_train[:, feature_idx].max(), 1000).reshape(-1, 1)\n    \n    plt.figure(figsize=(8, 5))\n    \n    for c in classifier.classes:\n        if classifier.kde_models[c] is None:\n            continue\n        \n        kde = classifier.kde_models[c][feature_idx]\n        log_density = kde.score_samples(x_range)\n        density = np.exp(log_density)\n        \n        plt.plot(x_range, density, label=f'Class {c}')\n    \n    plt.xlabel(f'Feature {feature_idx}')\n    plt.ylabel('Density')\n    plt.title(f'Kernel Density Estimation (KDE) for Feature {feature_idx}')\n    plt.legend()\n    plt.show()\n\n# Example: Plot KDE for feature 0\nplot_kde(classifier, feature_idx=0, X_train=Train_features, y_train=y_train)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import gaussian_kde\nfrom sklearn.decomposition import PCA\n\n# Giả lập lại dữ liệu nếu cần\nnp.random.seed(0)\nX = Train_features\ny = y_train\n\n# Lấy dữ liệu của từng class\nclass0_data = X[y == 0]\nclass1_data = X[y == 1]\n\n# Tiến hành PCA để giảm chiều dữ liệu\npca = PCA(n_components=2)  # Chọn 2 thành phần chính để giảm chiều xuống 2D\nX_class0_pca = pca.fit_transform(class0_data)\nX_class1_pca = pca.fit_transform(class1_data)\n\n# Tính KDE bằng scipy\nkde_class0 = gaussian_kde(X_class0_pca.T)  # Sử dụng dữ liệu đã giảm chiều (chuyển vị)\nkde_class1 = gaussian_kde(X_class1_pca.T)\n\n# Tạo một lưới 2D (meshgrid) cho các giá trị của x và y\nx_min, x_max = np.min(X_class0_pca[:, 0]), np.max(X_class0_pca[:, 0])\ny_min, y_max = np.min(X_class0_pca[:, 1]), np.max(X_class0_pca[:, 1])\nx_range, y_range = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n\n# Làm phẳng lưới 2D thành một mảng 1D để tính KDE\ngrid_points = np.vstack([x_range.ravel(), y_range.ravel()])\n\n# Tính giá trị KDE cho lưới điểm 2D\nkde_vals_class0 = kde_class0(grid_points)\nkde_vals_class1 = kde_class1(grid_points)\n\n# Đưa các giá trị KDE vào lại dạng lưới 2D để vẽ\nkde_vals_class0_2d = kde_vals_class0.reshape(x_range.shape)\nkde_vals_class1_2d = kde_vals_class1.reshape(x_range.shape)\n\n# Vẽ biểu đồ\nplt.figure(figsize=(10, 5))\n\n# Vẽ lớp KDE Class 0 và Class 1\ncp0 = plt.contourf(x_range, y_range, kde_vals_class0_2d, levels=20, cmap='Blues', alpha=0.5)\ncp1 = plt.contourf(x_range, y_range, kde_vals_class1_2d, levels=20, cmap='Reds', alpha=0.5)\n\n# Thêm nhãn cho Class 0 và Class 1\nplt.title(\"Kernel density function for Class 0 and Class 1\")\nplt.xlabel(\"Principal Component 1\")\nplt.ylabel(\"Principal Component 2\")\n\n# Thêm thanh màu (colorbar)\nplt.colorbar(label=\"Kernel density function\")\n\n# Thêm text vào plot cho KDE1 và KDE2\nplt.text(-2.0, -1, '$f_1$', color='blue', fontsize=9)\nplt.text(-2.4, -0.25, '$f_2$', color='blue', fontsize=9)\n\n# Hiển thị lưới và điều chỉnh bố cục\nplt.grid(True)\nplt.tight_layout()\n\n# Lưu và hiển thị đồ thị\nplt.savefig('2DKDF_with_labels_in_plot.png')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import gaussian_kde\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Giả lập lại dữ liệu nếu cần\nnp.random.seed(0)\nX = Train_features\ny = y_train\n\n# Lấy dữ liệu của từng class\nclass0_data = X[y == 0]\nclass1_data = X[y == 1]\n\n# Tiến hành PCA để giảm chiều dữ liệu\npca = PCA(n_components=2)  # Chọn 2 thành phần chính để giảm chiều xuống 2D\nX_class0_pca = pca.fit_transform(class0_data)\nX_class1_pca = pca.fit_transform(class1_data)\n\n# Tính KDE bằng scipy\nkde_class0 = gaussian_kde(X_class0_pca.T)  # Sử dụng dữ liệu đã giảm chiều (chuyển vị)\nkde_class1 = gaussian_kde(X_class1_pca.T)\n\n# Tạo một lưới 2D (meshgrid) cho các giá trị của x và y\nx_min, x_max = np.min(X_class0_pca[:, 0]), np.max(X_class0_pca[:, 0])\ny_min, y_max = np.min(X_class0_pca[:, 1]), np.max(X_class0_pca[:, 1])\nx_range, y_range = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n\n# Làm phẳng lưới 2D thành một mảng 1D để tính KDE\ngrid_points = np.vstack([x_range.ravel(), y_range.ravel()])\n\n# Tính giá trị KDE cho lưới điểm 2D\nkde_vals_class0 = kde_class0(grid_points)\nkde_vals_class1 = kde_class1(grid_points)\n\n# Đưa các giá trị KDE vào lại dạng lưới 2D để vẽ\nkde_vals_class0_2d = kde_vals_class0.reshape(x_range.shape)\nkde_vals_class1_2d = kde_vals_class1.reshape(x_range.shape)\n\n# Vẽ biểu đồ 3D\nfig = plt.figure(figsize=(12, 8))\nax = fig.add_subplot(111, projection='3d')\n\n# Tạo mặt phẳng 3D cho KDE Class 0\nax.plot_surface(x_range, y_range, kde_vals_class0_2d, cmap='Blues', alpha=0.7)\n\n# Tạo mặt phẳng 3D cho KDE Class 1\nax.plot_surface(x_range, y_range, kde_vals_class1_2d, cmap='Reds', alpha=0.7)\n\n#ax.set_title(\"KDE for Class 0 and Class 1\")\nax.set_xlabel(\"Principal Component 1\")\nax.set_ylabel(\"Principal Component 2\")\nax.set_zlabel(\"Kernel density function\")\n# Thêm label cho KDE1 và KDE2\nax.text(-2, -0.5, np.max(kde_vals_class0_2d), \"$f_1$\", color=\"blue\", fontsize=14, weight='bold')\nax.text(-2.3, -0.3, np.max(kde_vals_class1_2d), \"$f_2$\", color=\"blue\", fontsize=14, weight='bold')\n\nplt.tight_layout()\nplt.savefig('2DKDF2b.png')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import gaussian_kde\n\n# Giả lập lại dữ liệu nếu cần\nnp.random.seed(0)\nX = Train_features\ny = y_train\n\n# Lấy dữ liệu của từng class (1D trong trường hợp này)\nclass0_data = X[y == 0]\nclass1_data = X[y == 1]\n\n# Chọn một chiều dữ liệu (VD: sử dụng chiều đầu tiên của dữ liệu)\nclass0_data_1d = class0_data[:, 0]  # Chọn chiều đầu tiên\nclass1_data_1d = class1_data[:, 0]  # Chọn chiều đầu tiên\n\n# Tính KDE cho mỗi class\nkde_class0 = gaussian_kde(class0_data_1d)\nkde_class1 = gaussian_kde(class1_data_1d)\n\n# Tạo lưới điểm cho đồ thị\nx_range = np.linspace(-4, 4, 1000)\n\n# Tính giá trị KDE cho lưới điểm\nkde_vals_class0 = kde_class0(x_range)\nkde_vals_class1 = kde_class1(x_range)\n\n# Vẽ đồ thị 1D KDE\nplt.figure(figsize=(10, 6))\nplt.plot(x_range, kde_vals_class0, label='KDE Class 0 (Cancer)', color='blue', linewidth=2)\nplt.plot(x_range, kde_vals_class1, label='KDE Class 1 (Normal)', color='red', linewidth=2)\n\n# Thêm nhãn và tiêu đề\n#plt.title(\"Kernel density function for Class 0 (Cancer) and Class 1 (Normal)\", fontsize=16)\nplt.xlabel(\"Value (x)\", fontsize=14)\nplt.ylabel(\"Kernel density function \", fontsize=14)\nplt.legend()\n\n# Hiển thị đồ thị\nplt.grid(True)\nplt.tight_layout()\nplt.savefig('1DKDF.png')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_avg_kde(classifier, X_train, num_features=768, num_points=1000):\n    # Xác định range dùng chung cho tất cả feature\n    min_val = X_train.min()\n    max_val = X_train.max()\n    x_range = np.linspace(min_val, max_val, num_points).reshape(-1, 1)\n    \n    plt.figure(figsize=(8, 5))\n\n    for c in classifier.classes:\n        avg_density = np.zeros_like(x_range.flatten())\n        valid_feature_count = 0\n\n        for feature_idx in range(num_features):\n            kde = classifier.kde_models[c][feature_idx]\n            if kde is None:\n                continue\n\n            log_density = kde.score_samples(x_range)\n            density = np.exp(log_density)\n            avg_density += density\n            valid_feature_count += 1\n\n        if valid_feature_count > 0:\n            avg_density /= valid_feature_count\n            plt.plot(x_range, avg_density, label=f'Class {c}')\n    \n    plt.xlabel('Feature Value')\n    plt.ylabel('Average Density')\n    plt.title('Average KDE over 768 Features')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n# Gọi hàm để vẽ KDE trung bình cho 768 feature\nplot_avg_kde(classifier, X_train=Train_features, num_features=768)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_prior_pie(classifier):\n    plt.figure(figsize=(6, 6))\n    \n    # Replace 0 and 1 with \"Normal\" and \"Cancer\"\n    labels = ['Normal' if c == 1 else 'Cancer' for c in classifier.priors.keys()]\n    sizes = list(classifier.priors.values())\n\n    plt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=plt.cm.Paired.colors, startangle=140)\n    plt.title(\"Prior Probability\")\n    plt.savefig('Prior_Probability.png', dpi=300, bbox_inches='tight')  \n    plt.show()\n\n# Example usage\nplot_prior_pie(classifier)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**2. Naive bayes**","metadata":{}},{"cell_type":"code","source":"st=time.time()\n# Step 5: Train a Naive Bayes Classifier  \nclassifier = GaussianNB()  \nclassifier.fit(Train_features,y_train)  # Training the classifier  \n\n# Step 6: Make Predictions  \ny_pred = classifier.predict(Test_features)  \n\n# Step 7: Evaluate the Model  \nprint(\"Accuracy:\", accuracy_score(y_test,y_pred))  \nprint(classification_report(y_test,y_pred))  \nnd=time.time()\nprint(\"Thoi gian thu thi\", nd-st)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n# Step 7: Evaluate the Model and Compute Confusion Matrix\nconf_matrix = confusion_matrix(y_test, y_pred)  # Define conf_matrix here\n\n# Figure 1: Confusion Matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n            xticklabels=categories, yticklabels=categories)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.savefig('confusion_matrix.png')\nplt.show\n# plt.close()\n# print(\"Confusion matrix figure saved as 'confusion_matrix.png'.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 8: Show the locations of errors (misclassifications) and their classes\nerror_indices = (y_test != y_pred)  # Boolean array where True means misclassified\n\n# Display the misclassified indices and their true/predicted labels\nfor idx in error_indices.nonzero()[0]:  # Loop through misclassified indices\n    print(f\"Index: {idx}, True Label: {y_test[idx]}, Predicted Label: {y_pred[idx]}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**3. Logistic regression**","metadata":{}},{"cell_type":"code","source":"import time\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Bắt đầu đo thời gian\nst = time.time()\n\n# Step 5: Train a Logistic Regression Classifier  \nclassifier = LogisticRegression(max_iter=1000)  # Tạo đối tượng LogisticRegression, điều chỉnh max_iter nếu cần thiết  \nclassifier.fit(Train_features, y_train)  # Huấn luyện mô hình\n\n# Step 6: Make Predictions  \ny_pred = classifier.predict(Test_features)  # Dự đoán với dữ liệu kiểm tra\n\n# Step 7: Evaluate the Model  \nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))  # Đánh giá độ chính xác\nprint(classification_report(y_test, y_pred))  # In báo cáo phân loại với các chỉ số chính\n\n# Kết thúc đo thời gian\nnd = time.time()\nprint(\"Thời gian thực thi:\", nd - st)  # In ra thời gian thực thi\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**4. XGBoost**","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report\nimport time\nst=time.time()\n# Encode target labels\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)  # Encoding train labels\ny_test_encoded = label_encoder.transform(y_test)  # Encoding test labels\n\n# Step 5: Train an XGBoost Classifier\nclassifier = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\nclassifier.fit(Train_features, y_train_encoded)  # Training the classifier with encoded labels  \n\n# Step 6: Make Predictions\ny_pred_encoded = classifier.predict(Test_features)\n\n# Step 7: Decode predictions back to original labels\ny_pred = label_encoder.inverse_transform(y_pred_encoded)\n\n# Step 8: Evaluate the Model\nprint(\"Accuracy:\", accuracy_score(y_test_encoded, y_pred))  # Compare with encoded test labels\nprint(classification_report(y_test_encoded, y_pred))  # Use encoded labels for report\nnd=time.time()\nprint(\"Thoi gian thu thi\", nd-st)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n# Step 7: Evaluate the Model and Compute Confusion Matrix\nconf_matrix = confusion_matrix(y_test_encoded, y_pred)  # Define conf_matrix here\n\n# Figure 1: Confusion Matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n            xticklabels=categories, yticklabels=categories)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.savefig('confusion_matrix.png')\nplt.show\n# plt.close()\n# print(\"Confusion matrix figure saved as 'confusion_matrix.png'.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**5. So sánh với thuật toán CNN**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import layers, models\nimport matplotlib.pyplot as plt\nst=time.time()\n# --- Step 1: Load and preprocess images from file paths ---\ndef load_images(image_paths, target_size=(64, 64)):\n    images = []\n    for path in image_paths:\n        img = cv2.imread(path)\n        img = cv2.resize(img, target_size)\n        img = img / 255.0  # Normalize to [0,1]\n        images.append(img)\n    return np.array(images)\n\n# Create train-test split  \nX_train, X_test, y_train, y_test = train_test_split(  \n    image_paths,  \n    labels,  \n    test_size=0.2,  # 20% of data will be used as test set  \n    random_state=42,  # For reproducibility \n) \nfrom sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(y_train)  # Encoding train labels\ny_test = label_encoder.transform(y_test)  # Encoding test labels\n\n\n# Convert to categorical (one-hot encoding)\nnum_classes = len(label_encoder.classes_)\ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)\n\n# --- Step 5: Load actual image data ---\nx_train = load_images(X_train)\nx_test = load_images(X_test)\n\n# --- Step 6: Build CNN model ---\nmodel = models.Sequential([\n    layers.Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)),\n    layers.MaxPooling2D((2,2)),\n\n    layers.Conv2D(64, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n\n    layers.Conv2D(128, (3,3), activation='relu'),\n    layers.Flatten(),\n\n    layers.Dense(128, activation='relu'),\n    layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# --- Step 7: Train the model ---\nhistory = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n\n# --- Step 8: Evaluate the model ---\ntest_loss, test_acc = model.evaluate(x_test, y_test)\nprint(f\"\\n🎯 Test Accuracy: {test_acc:.4f}\")\nnd=time.time()\nprint(\"Thoi gian thu thi\", nd-st)\n\n# --- Step 9: Plot training history ---\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training vs Validation Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}